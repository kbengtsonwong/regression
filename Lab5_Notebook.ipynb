{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Linear Regression Lab 5 — Kevin Wong_#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinwong2014/anaconda/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(style=\"whitegrid\")\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import t as tdist\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dataset Context **\n",
    "\n",
    "In the computational section of this Lab you will consider the baseball dataset found in\n",
    "the file hitters.csv. This dataset records the salary of  n = 263 Major League Baseball\n",
    "players during the 1987 season as well as q = 19 statistics associated with the\n",
    "performance of each player during the previous season. Specifically, the dataset contains\n",
    "observations from the following variables:\n",
    "- AtBat: Number of times at bat in 1986\n",
    "- Hits: Number of hits in 1986\n",
    "- HmRun: Number of home runs in 1986\n",
    "- Runs: Number of runs in 1986\n",
    "- RBI: Number of runs batted in in 1986\n",
    "- Walks: Number of walks in 1986\n",
    "- Years: Number of years in the major leagues\n",
    "- CAtBat: Number of times at bat during his career\n",
    "- CHits: Number of hits during his career\n",
    "- CHmRun: Number of home runs during his career\n",
    "- CRuns: Number of runs during his career\n",
    "- CRBI: Number of runs batted in during his career\n",
    "- CWalks: Number of walks during his career\n",
    "- League: A categorical variable with levels A (for American) and N (for National) indicating the player’s league at the end of 1986\n",
    "- Division: A factor with levels E (for East) and W (for West) indicating the player’s division at the end of 1986\n",
    "- PutOuts: Number of put outs in 1986\n",
    "- Assists: Number of assists in 1986\n",
    "- Errors: Number of errors in 1986\n",
    "- Salary: 1987 annual salary on opening day in thousands of dollars\n",
    "- NewLeague: A factor with levels A and N indicating the player’s league at the beginning of 1987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Data in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 20 columns):\n",
      "AtBat        263 non-null int64\n",
      "Hits         263 non-null int64\n",
      "HmRun        263 non-null int64\n",
      "Runs         263 non-null int64\n",
      "RBI          263 non-null int64\n",
      "Walks        263 non-null int64\n",
      "Years        263 non-null int64\n",
      "CAtBat       263 non-null int64\n",
      "CHits        263 non-null int64\n",
      "CHmRun       263 non-null int64\n",
      "CRuns        263 non-null int64\n",
      "CRBI         263 non-null int64\n",
      "CWalks       263 non-null int64\n",
      "League       263 non-null object\n",
      "Division     263 non-null object\n",
      "PutOuts      263 non-null int64\n",
      "Assists      263 non-null int64\n",
      "Errors       263 non-null int64\n",
      "Salary       263 non-null float64\n",
      "NewLeague    263 non-null object\n",
      "dtypes: float64(1), int64(16), object(3)\n",
      "memory usage: 85.9 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"hitters.csv\") \n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.500</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>185</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>76</td>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>70.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>298</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>509</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>121</td>\n",
       "      <td>283</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>323</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>341</td>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>143</td>\n",
       "      <td>290</td>\n",
       "      <td>19</td>\n",
       "      <td>75.000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401</td>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>5206</td>\n",
       "      <td>1332</td>\n",
       "      <td>253</td>\n",
       "      <td>784</td>\n",
       "      <td>890</td>\n",
       "      <td>866</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>574</td>\n",
       "      <td>159</td>\n",
       "      <td>21</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>4631</td>\n",
       "      <td>1300</td>\n",
       "      <td>90</td>\n",
       "      <td>702</td>\n",
       "      <td>504</td>\n",
       "      <td>488</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>238</td>\n",
       "      <td>445</td>\n",
       "      <td>22</td>\n",
       "      <td>517.143</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "0    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "1    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "2    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "3    321    87     10    39   42     30      2     396    101      12     48   \n",
       "4    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "5    185    37      1    23    8     21      2     214     42       1     30   \n",
       "6    298    73      0    24   24      7      3     509    108       0     41   \n",
       "7    323    81      6    26   32      8      2     341     86       6     32   \n",
       "8    401    92     17    49   66     65     13    5206   1332     253    784   \n",
       "9    574   159     21   107   75     59     10    4631   1300      90    702   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors    Salary NewLeague  \n",
       "0   414     375      N        W      632       43      10   475.000         N  \n",
       "1   266     263      A        W      880       82      14   480.000         A  \n",
       "2   838     354      N        E      200       11       3   500.000         N  \n",
       "3    46      33      N        E      805       40       4    91.500         N  \n",
       "4   336     194      A        W      282      421      25   750.000         A  \n",
       "5     9      24      N        E       76      127       7    70.000         A  \n",
       "6    37      12      A        W      121      283       9   100.000         A  \n",
       "7    34       8      N        W      143      290      19    75.000         N  \n",
       "8   890     866      A        E        0        0       0  1100.000         A  \n",
       "9   504     488      A        E      238      445      22   517.143         A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "** A) Calculate the variance inflation factor (VIF) for each of the explanatory variables.\n",
    "Comment on whether multicollinearity appears to be an issue. If it is, identify the\n",
    "three explanatory variables that are most seriously affected by the issue. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF atbat:  22.9443659168\n",
      "VIF hits:  30.2812553305\n",
      "VIF HmRun:  30.2812553305\n",
      "VIF hits:  15.2464175021\n",
      "VIF RBI:  11.9217150823\n",
      "VIF Walks:  4.14871197167\n",
      "VIF Years:  9.31327990234\n",
      "VIF CAtBat:  251.561159565\n",
      "VIF CHits:  502.954289038\n",
      "VIF CHmRun:  46.4884615297\n",
      "VIF CRuns:  162.52081015\n",
      "VIF CRBI:  131.965857676\n",
      "VIF CWalks:  19.7441050138\n",
      "VIF PutOuts:  1.23631696225\n",
      "VIF Assists:  2.70934093676\n",
      "VIF Errors:  2.21454346669\n"
     ]
    }
   ],
   "source": [
    "m_atbat = smf.ols(\"AtBat ~ Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_atbat = 1 / (1 - m_atbat.rsquared)\n",
    "print(\"VIF atbat: \", VIF_atbat)\n",
    "\n",
    "m_hits = smf.ols(\"Hits ~ AtBat + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_hits = 1 / (1 - m_hits.rsquared)\n",
    "print(\"VIF hits: \", VIF_hits)\n",
    "\n",
    "m_hmrun = smf.ols(\"Hits ~ AtBat + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_hmrun = 1 / (1 - m_hmrun.rsquared)\n",
    "print(\"VIF HmRun: \", VIF_hmrun)\n",
    "\n",
    "m_runs = smf.ols(\"Runs ~ AtBat + Hits + HmRun + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_runs = 1 / (1 - m_runs.rsquared)\n",
    "print(\"VIF hits: \", VIF_runs)\n",
    "\n",
    "m_rbi = smf.ols(\"RBI ~ AtBat + Hits + HmRun + Runs + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_rbi = 1 / (1 - m_rbi.rsquared)\n",
    "print(\"VIF RBI: \", VIF_rbi)\n",
    "\n",
    "m_walks = smf.ols(\"Walks ~ AtBat + Hits + HmRun + Runs + RBI + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_walks = 1 / (1 - m_walks.rsquared)\n",
    "print(\"VIF Walks: \", VIF_walks)\n",
    "\n",
    "m_years = smf.ols(\"Years ~ AtBat + Hits + HmRun + Runs + RBI + Walks + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_years = 1 / (1 - m_years.rsquared)\n",
    "print(\"VIF Years: \", VIF_years)\n",
    "\n",
    "m_catbat = smf.ols(\"CAtBat ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_catbat = 1 / (1 - m_catbat.rsquared)\n",
    "print(\"VIF CAtBat: \", VIF_catbat)\n",
    "\n",
    "m_chits = smf.ols(\"CHits ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_chits = 1 / (1 - m_chits.rsquared)\n",
    "print(\"VIF CHits: \", VIF_chits)\n",
    "\n",
    "m_chmrun = smf.ols(\"CHmRun ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_chmrun = 1 / (1 - m_chmrun.rsquared)\n",
    "print(\"VIF CHmRun: \", VIF_chmrun)\n",
    "\n",
    "m_cruns = smf.ols(\"CRuns ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_cruns = 1 / (1 - m_cruns.rsquared)\n",
    "print(\"VIF CRuns: \", VIF_cruns)\n",
    "\n",
    "m_crbi = smf.ols(\"CRBI ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_crbi = 1 / (1 - m_crbi.rsquared)\n",
    "print(\"VIF CRBI: \", VIF_crbi)\n",
    "\n",
    "m_cwalks = smf.ols(\"CWalks ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_cwalks = 1 / (1 - m_cwalks.rsquared)\n",
    "print(\"VIF CWalks: \", VIF_cwalks)\n",
    "\n",
    "m_putouts = smf.ols(\"PutOuts ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_putouts = 1 / (1 - m_putouts.rsquared)\n",
    "print(\"VIF PutOuts: \", VIF_putouts)\n",
    "\n",
    "m_assists = smf.ols(\"Assists ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Errors + C(NewLeague)\", data = df).fit()\n",
    "VIF_assists = 1 / (1 - m_assists.rsquared)\n",
    "print(\"VIF Assists: \", VIF_assists)\n",
    "\n",
    "m_errors = smf.ols(\"Errors ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + C(NewLeague)\", data = df).fit()\n",
    "VIF_errors = 1 / (1 - m_errors.rsquared)\n",
    "print(\"VIF Errors: \", VIF_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, there does appear to be an issue of multicollinearity between several columns in the dataset.  The most significant variables with the highest VIFs are CHits, CAtBat, and CRuns.   This makes sense, as these are all career length metrics that track in essence how much someone has played.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "** Parts B) - E) completed using R specific libraries — R code attached.  **\n",
    "<n>** Algorithm explanations: **\n",
    "\n",
    "<n><i> All-Possible-Subsets approach</i>:  This method involves fitting all possible combinations of models uisng the explanatory variables and choosing the best one using evaluation metrics that penalize for increased numbers of explanatory terms (e.g. R-adj, BIC, AIC).  We fit $2^q$ models in total, choosing the best model within each \"bucket\" of models with a certain number of explanatory variables.  We then compare the best of each bucket and choose the one with the best goodness-of-fit metric, aka the optimized model.   \n",
    "\n",
    "<n><i> Forward Selection</i>: This variant of stepwise selection begins with the smallest model — the intercept only model — and iterates forward by considering adding one more explanatory variable if it improves on a goodness-of-fit metric.  We continue to add explanatory variables one at a time until no further improvements can be made. \n",
    "\n",
    "<n><i> Backward Selection</i>: This variant of stepwise selection is like forward selection, only in reverse.  It starts with the bigest model and considers dropping the least influential explanatory variable, seeing if the goodness-of-fit metric can be improved by dropping it.  If it can, we drop the variable and then consider dropping one of the variables that remain until no improvements can be made.\n",
    "\n",
    "<n><i> Hybrid Selection</i>: A combination of the previous two approaches, it starts with the bare intercept-only model and proceeds forward by considering to add one explanatory variable.  If adding an explanatory variable improves the metric, we add it.  Then, at each subsequent stage, we consider adding the most influential variable or eliminating the least influential variable — whichever improves the model the most.  We continue until no further improvements can be made.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "** F) In this part you will compare the predictive performance of four models: **\n",
    "- The full model with all 19 explanatory variables.\n",
    "- The optimal model identified in part (b).\n",
    "- The best model from parts (c)-(e) (i.e., the best stepwise-selection model).\n",
    "- The model that is considered optimal with respect to the Bayesian Information Criterion (BIC) which contains the variables AtBat, Hits, Walks, CRBI, Division and PutOuts. \n",
    "\n",
    "Randomly split the observed data into a training set (containing roughly 80% of\n",
    "all of the data) and a held-out test set (containing roughly 20% of all of the data).\n",
    "Calculate the predictive root-mean-square error (RMSE) for each of the four\n",
    "models. Which model appears to be most appropriate? Justify why this model is\n",
    "most appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398.187775948\n"
     ]
    }
   ],
   "source": [
    "# the full model\n",
    "m_full = smf.ols(\"Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists + Errors + C(NewLeague)\", data = df).fit()\n",
    "X_full = df[[\"AtBat\",\"Hits\",\"HmRun\",\"Runs\",\"RBI\",\"Walks\",\"Years\",\"CAtBat\",\"CHits\",\"CHmRun\",\"CRuns\",\"CRBI\",\"CWalks\",\"League\",\"Division\",\"PutOuts\",\"Assists\",\"Errors\",\"NewLeague\"]]\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size = 0.2)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "pred = m_full.predict(X_test)\n",
    "RMSE_full = np.sqrt(np.mean((y_test - pred)**2))\n",
    "print(RMSE_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289.705274268\n"
     ]
    }
   ],
   "source": [
    "# from results in R we find the:\n",
    "# optimal model with 11 explanatory variables\n",
    "m_optimal = smf.ols(\"Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + C(League) + C(Division) + PutOuts + Assists\", data = df).fit()\n",
    "X_optimal = df[[\"AtBat\",\"Hits\",\"Walks\",\"CAtBat\",\"CRuns\",\"CRBI\",\"CWalks\",\"League\",\"Division\",\"PutOuts\",\"Assists\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_optimal, y, test_size = 0.2)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "pred = m_optimal.predict(X_test)\n",
    "RMSE_optimal = np.sqrt(np.mean((y_test - pred)**2))\n",
    "print(RMSE_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318.264723417\n"
     ]
    }
   ],
   "source": [
    "# the best stepwise selection model \n",
    "m_stepwise = smf.ols(\"Salary ~ CRBI + Hits + PutOuts + C(Division) + AtBat +  Walks + CWalks + CRuns + CAtBat + Assists\", data = df).fit()\n",
    "X_stepwise = df[[\"CRBI\",\"Hits\",\"PutOuts\",\"Division\",\"AtBat\",\"Walks\",\"CWalks\",\"CRuns\",\"CAtBat\",\"Assists\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_stepwise, y, test_size = 0.2)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "pred = m_stepwise.predict(X_test)\n",
    "RMSE_stepwise = np.sqrt(np.mean((y_test - pred)**2))\n",
    "print(RMSE_stepwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290.602586725\n"
     ]
    }
   ],
   "source": [
    "# the model considered optimal w.r.t. the Bayesian Information Criterion \n",
    "m_bic = smf.ols(\"Salary ~ AtBat +  Hits + Walks + CRBI + C(Division) + PutOuts\", data = df).fit()\n",
    "X_bic = df[[\"AtBat\",\"Hits\",\"Walks\",\"CRBI\",\"Division\",\"PutOuts\"]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bic, y, test_size = 0.2)\n",
    "train = pd.concat([X_train, y_train], axis = 1)\n",
    "pred = m_bic.predict(X_test)\n",
    "RMSE_bic = np.sqrt(np.mean((y_test - pred)**2))\n",
    "print(RMSE_bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based purely off of one permutation of data into training and testing sets, we see that the RMSE of all the models all are in roughly the same 200-400 range.  Specifically, the root mean squared error of the optimal model from part B is lowest, so it appears to be the most appropriate.  Moreover, the methodology of this approach is the most complete when considered from a goodness-of-fit perspective, as we have optimized for an accuracy metric that penalizes more terms.  Ideally, we want the simplest, most powerful model.  The stepwise model is just a faster approximation of the model from the optimal all-possible-subsets approach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**G) As in part F, you must compare the predictive performance of the same four\n",
    "models, but here you must determine the predictive accuracy (predictive RMSE)\n",
    "by using 10-Fold Cross Validation. Which model appears to be most appropriate?\n",
    "Justify why this model is most appropriate. ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303.0815240701595"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K-fold Cross Validation on the full model\n",
    "numfolds = 10\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "MSE = 0\n",
    "for train_index, test_index in kf.split(X_full):\n",
    "    train_X, test_X = X_full.loc[train_index], X_full.loc[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    pred = m_full.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE_full = np.sqrt(MSE/numfolds)\n",
    "RMSE_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304.29513119942254"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K-fold Cross Validation on the optimal model\n",
    "numfolds = 10\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "MSE = 0\n",
    "for train_index, test_index in kf.split(X_optimal):\n",
    "    train_X, test_X = X_optimal.loc[train_index], X_optimal.loc[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    pred = m_optimal.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE_optimal = np.sqrt(MSE/numfolds)\n",
    "RMSE_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304.84833646250286"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K-fold Cross Validation on the stepwise model\n",
    "numfolds = 10\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "MSE = 0\n",
    "for train_index, test_index in kf.split(X_stepwise):\n",
    "    train_X, test_X = X_stepwise.loc[train_index], X_stepwise.loc[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    pred = m_stepwise.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE_stepwise = np.sqrt(MSE/numfolds)\n",
    "RMSE_stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315.20901854824081"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## K-fold Cross Validation on the BIC model\n",
    "numfolds = 10\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True)\n",
    "MSE = 0\n",
    "for train_index, test_index in kf.split(X_bic):\n",
    "    train_X, test_X = X_bic.loc[train_index], X_bic.loc[test_index]\n",
    "    train_y, test_y = y[train_index], y[test_index]\n",
    "    training = pd.concat([train_X, train_y], axis = 1)\n",
    "    pred = m_bic.predict(test_X)\n",
    "    MSE = MSE + np.mean((test_y - pred)**2)\n",
    "RMSE_bic = np.sqrt(MSE/numfolds)\n",
    "RMSE_bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the k-fold RMSE calculations, it is hard to justify any one model as the singularly best as the first three are all so close in range.  Due to methodology, we know the optimal model will be as good or better than the stepwise model.  Considering the full model versus the optimal model, using BIC metrics, the optimal model is better.  However, looking at predictive RMSE, they are roughly equal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**H) Given the estimates of predictive accuracy from parts F and G indicate which\n",
    "estimates you believe to be more accurate. In other words, indicate which\n",
    "validation approach (i.e., cross validation vs. k-fold cross validation) you believe\n",
    "will most accurately estimate the predictive capability of a model. Briefly explain\n",
    "your rationale.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-fold cross validation gives a more accurate estimate of the predictive capability of the model.  Rather than splitting the data just once into a training and testing set and seeing how the model performs on the test set, we effectively do this process k different times in k-fold cross validation, testing the k models on different test sets.  We therefore get a more average estimate of how the model performs, which is less biased than normal cross validation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "** I) Accounting for all of the analyses you’ve performed (i.e., multicollinearity,\n",
    "goodness-of-fit, and predictive accuracy), which model would you be most\n",
    "comfortable using? Briefly justify your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>7.84e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:10:14</td>     <th>  Log-Likelihood:    </th> <td> -1876.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3792.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   243</td>      <th>  BIC:               </th> <td>   3864.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>  163.1036</td> <td>   90.779</td> <td>    1.797</td> <td> 0.074</td> <td>  -15.710</td> <td>  341.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(League)[T.N]</th>    <td>   62.5994</td> <td>   79.261</td> <td>    0.790</td> <td> 0.430</td> <td>  -93.528</td> <td>  218.727</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Division)[T.W]</th>  <td> -116.8492</td> <td>   40.367</td> <td>   -2.895</td> <td> 0.004</td> <td> -196.363</td> <td>  -37.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(NewLeague)[T.N]</th> <td>  -24.7623</td> <td>   79.003</td> <td>   -0.313</td> <td> 0.754</td> <td> -180.380</td> <td>  130.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AtBat</th>             <td>   -1.9799</td> <td>    0.634</td> <td>   -3.123</td> <td> 0.002</td> <td>   -3.229</td> <td>   -0.731</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>              <td>    7.5008</td> <td>    2.378</td> <td>    3.155</td> <td> 0.002</td> <td>    2.818</td> <td>   12.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HmRun</th>             <td>    4.3309</td> <td>    6.201</td> <td>    0.698</td> <td> 0.486</td> <td>   -7.885</td> <td>   16.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Runs</th>              <td>   -2.3762</td> <td>    2.981</td> <td>   -0.797</td> <td> 0.426</td> <td>   -8.248</td> <td>    3.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RBI</th>               <td>   -1.0450</td> <td>    2.601</td> <td>   -0.402</td> <td> 0.688</td> <td>   -6.168</td> <td>    4.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Walks</th>             <td>    6.2313</td> <td>    1.829</td> <td>    3.408</td> <td> 0.001</td> <td>    2.630</td> <td>    9.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Years</th>             <td>   -3.4891</td> <td>   12.412</td> <td>   -0.281</td> <td> 0.779</td> <td>  -27.938</td> <td>   20.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAtBat</th>            <td>   -0.1713</td> <td>    0.135</td> <td>   -1.267</td> <td> 0.206</td> <td>   -0.438</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHits</th>             <td>    0.1340</td> <td>    0.675</td> <td>    0.199</td> <td> 0.843</td> <td>   -1.195</td> <td>    1.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHmRun</th>            <td>   -0.1729</td> <td>    1.617</td> <td>   -0.107</td> <td> 0.915</td> <td>   -3.358</td> <td>    3.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRuns</th>             <td>    1.4543</td> <td>    0.750</td> <td>    1.938</td> <td> 0.054</td> <td>   -0.024</td> <td>    2.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>              <td>    0.8077</td> <td>    0.693</td> <td>    1.166</td> <td> 0.245</td> <td>   -0.557</td> <td>    2.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CWalks</th>            <td>   -0.8116</td> <td>    0.328</td> <td>   -2.474</td> <td> 0.014</td> <td>   -1.458</td> <td>   -0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PutOuts</th>           <td>    0.2819</td> <td>    0.077</td> <td>    3.640</td> <td> 0.000</td> <td>    0.129</td> <td>    0.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Assists</th>           <td>    0.3711</td> <td>    0.221</td> <td>    1.678</td> <td> 0.095</td> <td>   -0.065</td> <td>    0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Errors</th>            <td>   -3.3608</td> <td>    4.392</td> <td>   -0.765</td> <td> 0.445</td> <td>  -12.011</td> <td>    5.290</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>87.414</td> <th>  Durbin-Watson:     </th> <td>   2.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 452.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.236</td> <th>  Prob(JB):          </th> <td>4.46e-99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.934</td> <th>  Cond. No.          </th> <td>2.09e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.546\n",
       "Model:                            OLS   Adj. R-squared:                  0.511\n",
       "Method:                 Least Squares   F-statistic:                     15.39\n",
       "Date:                Sun, 25 Nov 2018   Prob (F-statistic):           7.84e-32\n",
       "Time:                        23:10:14   Log-Likelihood:                -1876.2\n",
       "No. Observations:                 263   AIC:                             3792.\n",
       "Df Residuals:                     243   BIC:                             3864.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept           163.1036     90.779      1.797      0.074     -15.710     341.917\n",
       "C(League)[T.N]       62.5994     79.261      0.790      0.430     -93.528     218.727\n",
       "C(Division)[T.W]   -116.8492     40.367     -2.895      0.004    -196.363     -37.335\n",
       "C(NewLeague)[T.N]   -24.7623     79.003     -0.313      0.754    -180.380     130.855\n",
       "AtBat                -1.9799      0.634     -3.123      0.002      -3.229      -0.731\n",
       "Hits                  7.5008      2.378      3.155      0.002       2.818      12.184\n",
       "HmRun                 4.3309      6.201      0.698      0.486      -7.885      16.546\n",
       "Runs                 -2.3762      2.981     -0.797      0.426      -8.248       3.495\n",
       "RBI                  -1.0450      2.601     -0.402      0.688      -6.168       4.078\n",
       "Walks                 6.2313      1.829      3.408      0.001       2.630       9.833\n",
       "Years                -3.4891     12.412     -0.281      0.779     -27.938      20.960\n",
       "CAtBat               -0.1713      0.135     -1.267      0.206      -0.438       0.095\n",
       "CHits                 0.1340      0.675      0.199      0.843      -1.195       1.463\n",
       "CHmRun               -0.1729      1.617     -0.107      0.915      -3.358       3.013\n",
       "CRuns                 1.4543      0.750      1.938      0.054      -0.024       2.933\n",
       "CRBI                  0.8077      0.693      1.166      0.245      -0.557       2.172\n",
       "CWalks               -0.8116      0.328     -2.474      0.014      -1.458      -0.165\n",
       "PutOuts               0.2819      0.077      3.640      0.000       0.129       0.434\n",
       "Assists               0.3711      0.221      1.678      0.095      -0.065       0.807\n",
       "Errors               -3.3608      4.392     -0.765      0.445     -12.011       5.290\n",
       "==============================================================================\n",
       "Omnibus:                       87.414   Durbin-Watson:                   2.018\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              452.923\n",
       "Skew:                           1.236   Prob(JB):                     4.46e-99\n",
       "Kurtosis:                       8.934   Cond. No.                     2.09e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.09e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_full.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.543</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   27.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>8.93e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:10:14</td>     <th>  Log-Likelihood:    </th> <td> -1877.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3778.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   251</td>      <th>  BIC:               </th> <td>   3821.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>  135.7512</td> <td>   71.346</td> <td>    1.903</td> <td> 0.058</td> <td>   -4.762</td> <td>  276.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(League)[T.N]</th>   <td>   43.1116</td> <td>   39.966</td> <td>    1.079</td> <td> 0.282</td> <td>  -35.600</td> <td>  121.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Division)[T.W]</th> <td> -111.1460</td> <td>   39.218</td> <td>   -2.834</td> <td> 0.005</td> <td> -188.385</td> <td>  -33.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AtBat</th>            <td>   -2.1277</td> <td>    0.537</td> <td>   -3.959</td> <td> 0.000</td> <td>   -3.186</td> <td>   -1.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>             <td>    6.9237</td> <td>    1.646</td> <td>    4.206</td> <td> 0.000</td> <td>    3.682</td> <td>   10.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Walks</th>            <td>    5.6203</td> <td>    1.591</td> <td>    3.533</td> <td> 0.000</td> <td>    2.488</td> <td>    8.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAtBat</th>           <td>   -0.1390</td> <td>    0.056</td> <td>   -2.478</td> <td> 0.014</td> <td>   -0.249</td> <td>   -0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRuns</th>            <td>    1.4553</td> <td>    0.393</td> <td>    3.706</td> <td> 0.000</td> <td>    0.682</td> <td>    2.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>             <td>    0.7853</td> <td>    0.210</td> <td>    3.743</td> <td> 0.000</td> <td>    0.372</td> <td>    1.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CWalks</th>           <td>   -0.8229</td> <td>    0.264</td> <td>   -3.121</td> <td> 0.002</td> <td>   -1.342</td> <td>   -0.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PutOuts</th>          <td>    0.2894</td> <td>    0.075</td> <td>    3.870</td> <td> 0.000</td> <td>    0.142</td> <td>    0.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Assists</th>          <td>    0.2688</td> <td>    0.158</td> <td>    1.700</td> <td> 0.090</td> <td>   -0.043</td> <td>    0.580</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>88.563</td> <th>  Durbin-Watson:     </th> <td>   2.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 470.516</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.246</td> <th>  Prob(JB):          </th> <td>6.74e-103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.060</td> <th>  Cond. No.          </th> <td>1.39e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.543\n",
       "Model:                            OLS   Adj. R-squared:                  0.523\n",
       "Method:                 Least Squares   F-statistic:                     27.07\n",
       "Date:                Sun, 25 Nov 2018   Prob (F-statistic):           8.93e-37\n",
       "Time:                        23:10:14   Log-Likelihood:                -1877.2\n",
       "No. Observations:                 263   AIC:                             3778.\n",
       "Df Residuals:                     251   BIC:                             3821.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept          135.7512     71.346      1.903      0.058      -4.762     276.265\n",
       "C(League)[T.N]      43.1116     39.966      1.079      0.282     -35.600     121.823\n",
       "C(Division)[T.W]  -111.1460     39.218     -2.834      0.005    -188.385     -33.907\n",
       "AtBat               -2.1277      0.537     -3.959      0.000      -3.186      -1.069\n",
       "Hits                 6.9237      1.646      4.206      0.000       3.682      10.166\n",
       "Walks                5.6203      1.591      3.533      0.000       2.488       8.753\n",
       "CAtBat              -0.1390      0.056     -2.478      0.014      -0.249      -0.029\n",
       "CRuns                1.4553      0.393      3.706      0.000       0.682       2.229\n",
       "CRBI                 0.7853      0.210      3.743      0.000       0.372       1.198\n",
       "CWalks              -0.8229      0.264     -3.121      0.002      -1.342      -0.304\n",
       "PutOuts              0.2894      0.075      3.870      0.000       0.142       0.437\n",
       "Assists              0.2688      0.158      1.700      0.090      -0.043       0.580\n",
       "==============================================================================\n",
       "Omnibus:                       88.563   Durbin-Watson:                   2.011\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              470.516\n",
       "Skew:                           1.246   Prob(JB):                    6.74e-103\n",
       "Kurtosis:                       9.060   Cond. No.                     1.39e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.39e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_optimal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.64</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>2.80e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:10:14</td>     <th>  Log-Likelihood:    </th> <td> -1877.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3778.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   252</td>      <th>  BIC:               </th> <td>   3817.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>  162.5354</td> <td>   66.908</td> <td>    2.429</td> <td> 0.016</td> <td>   30.766</td> <td>  294.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Division)[T.W]</th> <td> -112.3801</td> <td>   39.214</td> <td>   -2.866</td> <td> 0.005</td> <td> -189.610</td> <td>  -35.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>             <td>    0.7743</td> <td>    0.210</td> <td>    3.694</td> <td> 0.000</td> <td>    0.362</td> <td>    1.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>             <td>    6.9180</td> <td>    1.647</td> <td>    4.201</td> <td> 0.000</td> <td>    3.675</td> <td>   10.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PutOuts</th>          <td>    0.2974</td> <td>    0.074</td> <td>    3.995</td> <td> 0.000</td> <td>    0.151</td> <td>    0.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AtBat</th>            <td>   -2.1687</td> <td>    0.536</td> <td>   -4.044</td> <td> 0.000</td> <td>   -3.225</td> <td>   -1.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Walks</th>            <td>    5.7732</td> <td>    1.585</td> <td>    3.643</td> <td> 0.000</td> <td>    2.652</td> <td>    8.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CWalks</th>           <td>   -0.8308</td> <td>    0.264</td> <td>   -3.152</td> <td> 0.002</td> <td>   -1.350</td> <td>   -0.312</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRuns</th>            <td>    1.4082</td> <td>    0.390</td> <td>    3.607</td> <td> 0.000</td> <td>    0.639</td> <td>    2.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAtBat</th>           <td>   -0.1301</td> <td>    0.055</td> <td>   -2.344</td> <td> 0.020</td> <td>   -0.239</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Assists</th>          <td>    0.2832</td> <td>    0.158</td> <td>    1.796</td> <td> 0.074</td> <td>   -0.027</td> <td>    0.594</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>91.407</td> <th>  Durbin-Watson:     </th> <td>   1.995</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 492.766</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.288</td> <th>  Prob(JB):          </th> <td>9.93e-108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.191</td> <th>  Cond. No.          </th> <td>1.28e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.540\n",
       "Model:                            OLS   Adj. R-squared:                  0.522\n",
       "Method:                 Least Squares   F-statistic:                     29.64\n",
       "Date:                Sun, 25 Nov 2018   Prob (F-statistic):           2.80e-37\n",
       "Time:                        23:10:14   Log-Likelihood:                -1877.8\n",
       "No. Observations:                 263   AIC:                             3778.\n",
       "Df Residuals:                     252   BIC:                             3817.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept          162.5354     66.908      2.429      0.016      30.766     294.305\n",
       "C(Division)[T.W]  -112.3801     39.214     -2.866      0.005    -189.610     -35.150\n",
       "CRBI                 0.7743      0.210      3.694      0.000       0.362       1.187\n",
       "Hits                 6.9180      1.647      4.201      0.000       3.675      10.161\n",
       "PutOuts              0.2974      0.074      3.995      0.000       0.151       0.444\n",
       "AtBat               -2.1687      0.536     -4.044      0.000      -3.225      -1.112\n",
       "Walks                5.7732      1.585      3.643      0.000       2.652       8.894\n",
       "CWalks              -0.8308      0.264     -3.152      0.002      -1.350      -0.312\n",
       "CRuns                1.4082      0.390      3.607      0.000       0.639       2.177\n",
       "CAtBat              -0.1301      0.055     -2.344      0.020      -0.239      -0.021\n",
       "Assists              0.2832      0.158      1.796      0.074      -0.027       0.594\n",
       "==============================================================================\n",
       "Omnibus:                       91.407   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              492.766\n",
       "Skew:                           1.288   Prob(JB):                    9.93e-108\n",
       "Kurtosis:                       9.191   Cond. No.                     1.28e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.28e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_stepwise.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Salary</td>      <th>  R-squared:         </th> <td>   0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   44.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 25 Nov 2018</td> <th>  Prob (F-statistic):</th> <td>6.82e-37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:10:14</td>     <th>  Log-Likelihood:    </th> <td> -1886.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   263</td>      <th>  AIC:               </th> <td>   3787.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   256</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   91.5118</td> <td>   65.000</td> <td>    1.408</td> <td> 0.160</td> <td>  -36.491</td> <td>  219.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Division)[T.W]</th> <td> -122.9515</td> <td>   39.820</td> <td>   -3.088</td> <td> 0.002</td> <td> -201.369</td> <td>  -44.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AtBat</th>            <td>   -1.8686</td> <td>    0.527</td> <td>   -3.543</td> <td> 0.000</td> <td>   -2.907</td> <td>   -0.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hits</th>             <td>    7.6044</td> <td>    1.663</td> <td>    4.574</td> <td> 0.000</td> <td>    4.330</td> <td>   10.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Walks</th>            <td>    3.6976</td> <td>    1.210</td> <td>    3.055</td> <td> 0.002</td> <td>    1.314</td> <td>    6.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRBI</th>             <td>    0.6430</td> <td>    0.064</td> <td>    9.979</td> <td> 0.000</td> <td>    0.516</td> <td>    0.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PutOuts</th>          <td>    0.2643</td> <td>    0.075</td> <td>    3.535</td> <td> 0.000</td> <td>    0.117</td> <td>    0.412</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>101.319</td> <th>  Durbin-Watson:     </th> <td>   2.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 615.052</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.411</td>  <th>  Prob(JB):          </th> <td>2.77e-134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 9.940</td>  <th>  Cond. No.          </th> <td>2.29e+03</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 Salary   R-squared:                       0.509\n",
       "Model:                            OLS   Adj. R-squared:                  0.497\n",
       "Method:                 Least Squares   F-statistic:                     44.18\n",
       "Date:                Sun, 25 Nov 2018   Prob (F-statistic):           6.82e-37\n",
       "Time:                        23:10:14   Log-Likelihood:                -1886.6\n",
       "No. Observations:                 263   AIC:                             3787.\n",
       "Df Residuals:                     256   BIC:                             3812.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           91.5118     65.000      1.408      0.160     -36.491     219.515\n",
       "C(Division)[T.W]  -122.9515     39.820     -3.088      0.002    -201.369     -44.534\n",
       "AtBat               -1.8686      0.527     -3.543      0.000      -2.907      -0.830\n",
       "Hits                 7.6044      1.663      4.574      0.000       4.330      10.878\n",
       "Walks                3.6976      1.210      3.055      0.002       1.314       6.081\n",
       "CRBI                 0.6430      0.064      9.979      0.000       0.516       0.770\n",
       "PutOuts              0.2643      0.075      3.535      0.000       0.117       0.412\n",
       "==============================================================================\n",
       "Omnibus:                      101.319   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              615.052\n",
       "Skew:                           1.411   Prob(JB):                    2.77e-134\n",
       "Kurtosis:                       9.940   Cond. No.                     2.29e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.29e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accounting for everything, the predictive RMSE scores suggest that the optimal or full model is best.  However, the multicollinearity test at the beginning showed that multicollinearity is a problem in our data, so we should be concerned about taking unimportant variables out of our model.  CHits is a variable with a very high VIF, which was taken out of the full model in the optimal model, along with other less important variables.  Thus, not only is the optimal model a simpler model that still has equivalent predictive power — it also has a marginally higher adjusted R-squared and explains a higher proportion of the variance.  Through a consideration of goodness-of-fit, predictive power, multicollinearity, and methodology we conclude that the all-possible-subsets optimal approach gives the best model.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
